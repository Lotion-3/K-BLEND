# SKALE-356

## Setup

Use requires linux terminal or ubuntu WSL.
WSL setup directions
1. Open command prompt run
```bash
wsl --install
```
2. Download ubuntu for WSL https://ubuntu.com/desktop/wsl
3. Open WSL

Virtual Environment setup  
```bash
git clone https://github.com/Lotion-3/SKALE-356
```
```bash
cd SKALE-356
```
```bash
sudo apt update
```
```bash
sudo apt install python3-venv
```
```bash
python3 -m venv SKALE356env
```
```bash
source SKALE356env/bin/activate
```
```bash
pip install -r req.txt
```

## Data Information  
This experiment utilized 11000 SARS-CoV-2 genomes from 11 strains. Alpha, Beta, Delta, Epsilon, Eta, Gamma, Iota, Lambda, Mu, Omicron  
Sourced from NGDC: https://ngdc.cncb.ac.cn/  
Full data set is available in rawFastas folder  
combine_fasta.py file combined all 11000 into comb11000.fasta and generated key.fasta.     

The data set was used to create the 13 splits described in the paper which were generated by using split.py   
Available in fullPaperFastas folder. Warning extracts to 20GB data set.  

Rest of tutorial uses sampleFastas data set containing only 2 splits.  
Available in sampleFastas folder. Extracts to 635MB.  

The complete tables used in the paper are available in fullPaperTables along with code used to generate figures.  

## SKALE-356 Usage  
Pre usage setup  
1. Bash Permissions  
```bash
chmod +x SKALE356.sh
```
2. Ramdisk setup
This example uses 8G of commited RAM, adjust to device specifications   
```bash
sudo mkdir -p /mnt/ramdisk
```
```bash
sudo mount -t tmpgs -o size=8G tmpfs /mnt/ramdisk
```
```bash
sudo chown $USER:$USER /mnt/ramdisk
```
```bash
echo always | sudo tee /sys/kernel/mm/transparent_hugepage/enabled
```
Run the SKALE356.sh file, this automated script trains 25 ensemble models and provides evaluation data.  
Execution arguments:  
```bash
./SKALE356.sh inputDirectory #cpuCores
```
The input directory expects two subdirectories, trainingFastas and testingFastas    
The script recognizes 2 naming systems for train test pairs  
1. Train: train%Train_11000_version# Test: test%test_11000_version#  
Ex. Train: train90_11000_5 Test: test10_11000_5  
Version numbers must match and percentages must add to 100  
2. Train: train_#sequences_version# Test: test_#sequences_version#   
Ex. Train: train_110_1 Test: test_10890_1  
Number of sequences must add to 11000 and version numbers must match  

The #cpuCores decides how many system cpuCores are dedicated to the execution.   
Train+Test pairs are processed simultaneously. Each dedicated core handles one pair.  
Default is half of system cores. Recommended maximum is the number of system cores -1.  

Usage with sampleFastas:  
```bash
./SKALE356.sh sampleFastas 2
```
Evaluation information is saved in the PIPELINE_HPC_RESULTS.csv file.  
Models are saved in saved_models/ directory.  

When finished clean ramdisk
```bash
sudo rm -r /mnt/ramdisk
```

## BLAST Benchmark usage
Download NCBI BLAST tool from: 
https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/  
Place in SKALE-356 directory  
Execution arguments:
```bash
python3 blastTesting.py inputDirectory
```
The input directory expects two subdirectories, trainingFastas and testingFastas    
The script recognizes 2 naming systems for train test pairs  
1. Train: train%Train_11000_version# Test: test%test_11000_version#  
Ex. Train: train90_11000_5 Test: test10_11000_5  
Version numbers must match and percentages must add to 100  
2. Train: train_#sequences_version# Test: test_#sequences_version#   
Ex. Train: train_110_1 Test: test_10890_1  
Number of sequences must add to 11000 and version numbers must match

Usage with sampleFastas:
```bash  
python3 blastTesting.py sampleFastas
```

Evaluation information is saved in blast_performance_metrics.csv  
Raw results in blastOutput folder  


